{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ccfa8412",
      "metadata": {
        "id": "ccfa8412"
      },
      "source": [
        "Training and Testing with stat-consult sensor measurements (IMU-ECG-Pressure)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras import layers\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "KyN0x8vFtZzV"
      },
      "id": "KyN0x8vFtZzV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d00580",
      "metadata": {
        "scrolled": false,
        "id": "53d00580"
      },
      "outputs": [],
      "source": [
        "# File folder_location for the dataset\n",
        "folder_path = 'C:/Users/val-c/Desktop/synchronised_measurements'\n",
        "# Get the list of all files in the folder_location\n",
        "file_list = os.listdir(folder_path)\n",
        "# Loop via the list of files & read them into pd\n",
        "dataframes = []\n",
        "for file_name in file_list:\n",
        "    if file_name.endswith(\".xlsx\"):  # respective activity files in excel format\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        df = pd.read_excel(file_path)\n",
        "        dataframes.append(df)\n",
        "# Combine all the files into a single dataframe\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "combined_df.head(n=8)  # display selected nos of rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8951a5b2",
      "metadata": {
        "id": "8951a5b2"
      },
      "outputs": [],
      "source": [
        "#Save the single_dataframe to a csv-file >> (built_homogenous_dataset)\n",
        "#combined_df.to_csv('built_homogenous_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746449d4",
      "metadata": {
        "id": "746449d4"
      },
      "outputs": [],
      "source": [
        "# Display info of the dataframe\n",
        "combined_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04fa337c",
      "metadata": {
        "id": "04fa337c"
      },
      "outputs": [],
      "source": [
        "# Convert \"ECG-Data\" column from integer to float\n",
        "combined_df[\"ECG-Data\"] = combined_df[\"ECG-Data\"].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f28c67",
      "metadata": {
        "id": "67f28c67"
      },
      "outputs": [],
      "source": [
        "# Class labels in the dataframe (df)\n",
        "unique_label = np.unique(combined_df.classes)\n",
        "class_label = np.sort(unique_label)\n",
        "print(class_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff941df3",
      "metadata": {
        "id": "ff941df3"
      },
      "outputs": [],
      "source": [
        "# Checking for missing values in the df\n",
        "combined_df.isna().sum(axis=0).to_frame('Total')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e611365a",
      "metadata": {
        "id": "e611365a"
      },
      "outputs": [],
      "source": [
        "# Plot the number of samples present in each class_label\n",
        "class_label = ['Standing still','Sitting and relaxing','Lying down','Walking', 'Climbing stairs',\n",
        "               'Waist bends forward', 'Frontal elevation of arms','Knees bending (crouching)', 'cycling',\n",
        "              'Jogging','Running','Jump front & back'] # ,\n",
        "plt.figure(figsize=(7, 6)) # figure sizing\n",
        "num_of_classes = len(class_label)\n",
        "# Creating barplot for the activitiy distribution in the df\n",
        "sns.barplot(x=class_label, y=combined_df[\"classes\"].value_counts(), color='olive', width=0.55)\n",
        "# Replace the numerical x-axis ticks with class labels\n",
        "plt.xticks(range(num_of_classes), class_label, rotation=45, ha='right')\n",
        "# the x_axis & y_axis labels, title\n",
        "plt.xlabel('\\nClasses', fontsize=10)\n",
        "plt.ylabel('\\nCount', fontsize=10)\n",
        "plt.title(\"\\n Activity distribution of the stat-consult dataset\", fontsize=12)\n",
        "#display plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa25381b",
      "metadata": {
        "id": "fa25381b"
      },
      "source": [
        "- Visualizing the measured data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9428bc",
      "metadata": {
        "scrolled": false,
        "id": "da9428bc"
      },
      "outputs": [],
      "source": [
        "# Performed activities\n",
        "activity_dict = {1: 'Standing still (1 min)',2: 'Sitting and relaxing (1 min)', 3: 'Lying down (1 min)', 4: 'Walking (1 min)',\n",
        "    5: 'Climbing stairs (1 min)',6: 'Waist bends forward (20x)',7: 'Frontal elevation of arms (20x)',8: 'Knees bending (crouching) (20x)',\n",
        "    9: 'Cycling (1 min)',10: 'Jogging (1 min)',11: 'Running (1 min)', 12: 'Jump front & back (20x)'}\n",
        "# Determining the number of rows and columns for subplots\n",
        "nos_row = len(activity_dict)\n",
        "nos_col = 5  # (accelerometer, gyroscope, magnetometer, ECG, and pressure)\n",
        "# Setting the subplots\n",
        "fig, axs = plt.subplots(nos_row, nos_col, figsize=(23, 5 * nos_row)) #(dpi=90)\n",
        "for i, activity_id in enumerate(activity_dict.keys()):\n",
        "    # Plot accelerometer measurements for the performed activities\n",
        "    axs[i, 0].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['a0X_LSM6DSL'], color='r', alpha=0.9)\n",
        "    axs[i, 0].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['a0Y_LSM6DSL'], color='b', alpha=0.9)\n",
        "    axs[i, 0].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['a0Z_LSM6DSL'], color='y', alpha=0.9)\n",
        "    axs[i, 0].set_title(f'{activity_dict[activity_id]} - Accelerometer', fontsize=13)\n",
        "    axs[i, 0].set_ylabel('Acceleration (m/s^2)', fontsize=12)\n",
        "    axs[i, 0].set_xlabel('Sample points', fontsize=11)\n",
        "    axs[i, 0].legend([\"acc. x\", \"acc. y\", \"acc. z\"], fontsize=9, loc=\"upper left\")\n",
        "    # Plot gyroscope measurements for the performed activities\n",
        "    axs[i, 1].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['g0X_LSM6DSL'], c='r', alpha=0.9)\n",
        "    axs[i, 1].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['g0Y_LSM6DSL'], c='b', alpha=0.9)\n",
        "    axs[i, 1].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['g0Z_LSM6DSL'], c='y', alpha=0.9)\n",
        "    axs[i, 1].set_title(f'{activity_dict[activity_id]} - Gyroscope', fontsize=13)\n",
        "    axs[i, 1].set_ylabel('Rotation (rad/s)', fontsize=12)\n",
        "    axs[i, 1].set_xlabel('Sample points', fontsize=11)\n",
        "    axs[i, 1].legend([\"gyro. x\", \"gyro. y\", \"gyro. z\"], fontsize=9, loc=\"upper left\")\n",
        "    # Plot magnetometer measurements for the performed activities\n",
        "    axs[i, 2].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['m0X_LSM303AH'], c='r', alpha=0.9)\n",
        "    axs[i, 2].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['m0Y_LSM303AH'], c='b', alpha=0.9)\n",
        "    axs[i, 2].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['m0Z_LSM303AH'], c='y', alpha=0.9)\n",
        "    axs[i, 2].set_title(f'{activity_dict[activity_id]} - Magnetometer', fontsize=13)\n",
        "    axs[i, 2].set_ylabel('Magnetic Field (mT)', fontsize=12)\n",
        "    axs[i, 2].set_xlabel('Sample points', fontsize=11)\n",
        "    axs[i, 2].legend([\"mag. x\", \"mag. y\", \"mag. z\"], fontsize=9, loc=\"upper left\")\n",
        "    # Plot ECG measurements for the performed activities\n",
        "    axs[i, 3].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['ECG-Data'], c='purple', alpha=0.9)\n",
        "    axs[i, 3].set_title(f'{activity_dict[activity_id]} - ECG', fontsize=13)\n",
        "    axs[i, 3].set_ylabel('Amplitude (v)', fontsize=12)\n",
        "    axs[i, 3].set_xlabel('Sample points', fontsize=11)\n",
        "    axs[i, 3].legend([\"ECG\"], fontsize=9, loc=\"upper left\")\n",
        "    # Plot Pressure measurements for the performed activities\n",
        "    axs[i, 4].plot(combined_df[combined_df['classes'] == activity_id].reset_index(drop=True)['Pres'], c='g', alpha=0.9)\n",
        "    axs[i, 4].set_title(f'{activity_dict[activity_id]} - Pressure', fontsize=13)\n",
        "    axs[i, 4].set_ylabel('atm (hPa)', fontsize=12)\n",
        "    axs[i, 4].set_xlabel('Sample points', fontsize=11)\n",
        "    axs[i, 4].legend([\"air-pressure\"], fontsize=9, loc=\"upper left\")\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "plt.show()# Display plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c2de39",
      "metadata": {
        "id": "41c2de39"
      },
      "outputs": [],
      "source": [
        "# Features and class from the dataframe\n",
        "Features =combined_df.copy() #features/input\n",
        "Label = Features.pop('classes') # class/output/target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250c2ade",
      "metadata": {
        "id": "250c2ade"
      },
      "outputs": [],
      "source": [
        "# Normalization of the features/input variables\n",
        "scaler = StandardScaler()\n",
        "normalized_feature = scaler.fit_transform(Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bfcd702",
      "metadata": {
        "id": "0bfcd702"
      },
      "outputs": [],
      "source": [
        "# Data-Segmentation\n",
        "# Creating function for the sliding-window\n",
        "#num_time_step: specifies the length of each segment/sequence\n",
        "#stepsize: specifies the step-size used to slide the window over the data\n",
        "def create_sequences(X, y, num_time_step, stepsize=1): # X:input y: output/target\n",
        "    segment, label = [],[]\n",
        "    for i in range(0,len(X) - num_time_step+1, stepsize):\n",
        "        x = X[i:i + num_time_step]\n",
        "        labels = y[i + num_time_step-1]\n",
        "        segment.append(x)\n",
        "        label.append(labels)\n",
        "    return np.array(segment), np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fefcf91",
      "metadata": {
        "id": "9fefcf91"
      },
      "outputs": [],
      "source": [
        "# Creating the data sequence\n",
        "X_seq, y_seq = create_sequences(normalized_feature, Label ,num_time_step=390, stepsize=195)\n",
        "# print shape of the data\n",
        "print(X_seq.shape, y_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395655ff",
      "metadata": {
        "id": "395655ff"
      },
      "outputs": [],
      "source": [
        "# Extract window_length,number of features, number of outputs to be used in the input & ouput of the neural network\n",
        "window_length,num_features,num_outputs= X_seq.shape[1], X_seq.shape[2],to_categorical(y_seq).shape[1]\n",
        "print(window_length,num_features,num_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1545701f",
      "metadata": {
        "scrolled": false,
        "id": "1545701f"
      },
      "outputs": [],
      "source": [
        "# Perform cross-validation\n",
        "scores = []\n",
        "# Creating the k-fold cross-validator\n",
        "kfold = KFold(n_splits=5, shuffle=True) # K=(n_splits)=5 >> total nos of samples/total nos of samples * % to be used as test data\n",
        "for i, (train, test) in enumerate(kfold.split(X_seq, y_seq)):\n",
        "    print(f'Fold {i}:')\n",
        "    print(train.shape)\n",
        "    print(test.shape)\n",
        "    # Convert output variables to categorical (one-hot encoding)\n",
        "    y_train_seq = to_categorical(y_seq[train])\n",
        "    y_test_seq = to_categorical(y_seq[test])\n",
        "\n",
        "    # Configuring the CNN-1D_LSTM network architecture\n",
        "    input_shape = (window_length, num_features)\n",
        "    model = keras.Sequential([\n",
        "        # Input layer\n",
        "        layers.Input(input_shape),\n",
        "        layers.Conv1D(filters=64, kernel_size=3, padding='same'), # CNN-1D layer-1\n",
        "        layers.BatchNormalization(), # batch_normalization\n",
        "        layers.Activation('relu'), # activation function\n",
        "        # Hidden Conv Layer\n",
        "        layers.Conv1D(filters=64, kernel_size=3, padding='same'), # CNN-1D layer-2\n",
        "        layers.BatchNormalization(), # batch_normalization\n",
        "        layers.Activation('relu'), # activation function\n",
        "        # Recurrent LSTM Layers\n",
        "        layers.LSTM(units=128, return_sequences=True), # LSTM layer-1\n",
        "        layers.Activation('relu'), # activation function\n",
        "        layers.LSTM(units=128, return_sequences=False), # LSTM layer-2\n",
        "        layers.Activation('relu'), # activation function\n",
        "        # Dense layers\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        # Activation function for the output layer 'softmax' for Multi-classification\n",
        "        layers.Dense(num_outputs, activation='softmax')])\n",
        "\n",
        "    # Compiling the model\n",
        "    initial_learning_rate = 0.001\n",
        "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate,\n",
        "        decay_steps=10,\n",
        "        decay_rate=0.9)\n",
        "    opt = keras.optimizers.RMSprop(learning_rate=lr_schedule)#optimizer\n",
        "    model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_seq[train], y_train_seq , validation_data=(X_seq[test], y_test_seq), epochs=10, batch_size=64)\n",
        "\n",
        "    # Predicting on the testing set\n",
        "    y_pred = model.predict(X_seq[test])\n",
        "    # Converting predictions to class_labels\n",
        "    predctd_label = np.argmax(y_pred, axis=1)\n",
        "    true_label = y_seq[test]\n",
        "\n",
        "    # Calculate accuracy score for the current fold\n",
        "    fold_accuracy = accuracy_score(true_label, predctd_label)\n",
        "    # Storing the accuracy score for the fold\n",
        "    scores.append(fold_accuracy)\n",
        "\n",
        "# Print the accuracy scores for each fold and finally compute the Mean accuracy\n",
        "print('\\n')\n",
        "print(scores)\n",
        "print('\\n')\n",
        "avg_acc = np.mean(scores)\n",
        "print(\"Mean_Accuracy:\", avg_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e10a0b",
      "metadata": {
        "id": "33e10a0b"
      },
      "outputs": [],
      "source": [
        "# Performance of the model on the testing set\n",
        "avg_accuracy_percent=avg_acc * 100\n",
        "# Print the mean accuracy\n",
        "print(f\"Mean_Accuracy: {avg_accuracy_percent:.1f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283f9e55",
      "metadata": {
        "id": "283f9e55"
      },
      "outputs": [],
      "source": [
        "# Classes of the the performed activities\n",
        "class_labels  = ['Standing still','Sitting and relaxing','Lying down','Walking','Climbing stairs',\n",
        "                 'Waist bends forward', 'Frontal elevation of arms','Knees bending (crouching)','Cycling',\n",
        "                 'Jogging','Running','Jump front & back']\n",
        "# Create a confusion matrix >> test set\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test_seq, axis=1),predctd_label)\n",
        "# Calculate accuracy percentages for each predicted activity labels\n",
        "class_lbl_accuracy = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "# Plot the confusion matrix with accuracy percentages for the predictions\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(class_lbl_accuracy, annot=True, fmt='.1f', cmap='OrRd', xticklabels=class_labels, yticklabels=class_labels, linewidths=0.5) #plot data\n",
        "plt.title('\\nConfusion Matrix : Testing Classification Accuracy (%)', fontsize=11, fontweight='bold')\n",
        "plt.xlabel('\\nPredicted Activities', fontsize=11, fontweight='bold')\n",
        "plt.ylabel('\\nActual Activities', fontsize=11, fontweight='bold')\n",
        "plt.show() # display plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710f2fc7",
      "metadata": {
        "id": "710f2fc7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}